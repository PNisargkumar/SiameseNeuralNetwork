{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFLiEonUv5cv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Sets\n",
        "1. AT&T faces (Modified)\n",
        "2. Omniglot (Single language - Gujarati)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = 1\n",
        "# Load the training dataset\n",
        "if dataset == 1:\n",
        "    folder_dataset = datasets.ImageFolder(root=r\"data\\faces\\training\")\n",
        "    folder_dataset_test = datasets.ImageFolder(root=r\"data\\faces\\testing/\")\n",
        "    print(f\"Dataset: AT&T faces (Modified)\\n\")\n",
        "elif dataset == 2:\n",
        "    folder_dataset = datasets.ImageFolder(root=r\"data\\Gujarati\\training\")\n",
        "    folder_dataset_test = datasets.ImageFolder(root=r\"data\\Gujarati\\testing/\")\n",
        "    print(f\"Dataset: Omniglot (Single language - Gujarati)\\n\")\n",
        "\n",
        "d_no_epochs = 50\n",
        "d_batch_size = 30\n",
        "d_margin = 2.0\n",
        "d_latent = 64\n",
        "print(f\"Summary of Training Folder:\\n {folder_dataset}\\n\")\n",
        "print(f\"Summary of Testing Folder:\\n {folder_dataset_test}\")\n",
        "\n",
        "# Resize the images and transform to tensors\n",
        "transformation = transforms.Compose([transforms.Resize((100,100)),\n",
        "                                        transforms.ToTensor()\n",
        "                                        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JaZWc1Nz07m"
      },
      "outputs": [],
      "source": [
        "# Creating some helper functions\n",
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "        \n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    \n",
        "\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Siamese Neural Network: CNN + FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create the Siamese Neural Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self,latent):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Setting up the Fully Connected Layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(384, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(256,latent)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for each images\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        # In this function we pass in given images and obtain laten space embeddings\n",
        "        output_anchor = self.forward_once(anchor)\n",
        "        output_positive = self.forward_once(positive)\n",
        "        output_negative = self.forward_once(negative)\n",
        "\n",
        "        return output_anchor, output_positive, output_negative"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD1BFFm_z7aj"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform=None,test=False):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "        self.test = test\n",
        "        self.files = iter(self.imageFolderDataset.imgs)\n",
        "        self.firstexec = True\n",
        "        self.current_file = next(self.files)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if not self.test:\n",
        "            anchor_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "            while True:\n",
        "                #Look untill the same class image is found\n",
        "                positive_tuple = random.choice(self.imageFolderDataset.imgs) \n",
        "                if (anchor_tuple[1] == positive_tuple[1]) and (anchor_tuple[0] != positive_tuple[0]):\n",
        "                    break\n",
        "\n",
        "\n",
        "            while True:\n",
        "                #Look untill a different class image is found\n",
        "                negative_tuple = random.choice(self.imageFolderDataset.imgs) \n",
        "                if anchor_tuple[1] != negative_tuple[1]:\n",
        "                    break\n",
        "            anchor = Image.open(anchor_tuple[0])\n",
        "            positive = Image.open(positive_tuple[0])\n",
        "            negative = Image.open(negative_tuple[0])\n",
        "            label = [anchor_tuple[0].split('\\\\')[-2]]\n",
        "        else:\n",
        "            if self.firstexec==True:\n",
        "                self.anchor_tuple = self.current_file              \n",
        "                self.current_file = next(self.files)\n",
        "                self.positive_tuple1 = self.current_file              \n",
        "                self.current_file = next(self.files)\n",
        "                self.firstexec = False\n",
        "                \n",
        "            if self.anchor_tuple[1] == self.current_file[1]:\n",
        "                positive_tuple2 = self.current_file\n",
        "                self.current_file=next(self.files)\n",
        "            else:\n",
        "                self.anchor_tuple = self.current_file              \n",
        "                self.current_file = next(self.files)\n",
        "                self.positive_tuple1 = self.current_file              \n",
        "                self.current_file = next(self.files)\n",
        "                positive_tuple2 = self.current_file\n",
        "\n",
        "            \n",
        "            anchor= Image.open(self.anchor_tuple[0])\n",
        "            positive= Image.open(self.positive_tuple1[0])\n",
        "            negative= Image.open(positive_tuple2[0])\n",
        "            label = [self.anchor_tuple[0].split('\\\\')[-2]]\n",
        "\n",
        "        anchor = anchor.convert(\"L\")\n",
        "        positive = positive.convert(\"L\")\n",
        "        negative = negative.convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            anchor = self.transform(anchor)\n",
        "            positive = self.transform(positive)\n",
        "            negative = self.transform(negative)\n",
        "        \n",
        "        \n",
        "        return anchor, positive, negative, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)\n",
        "    \n",
        "    def get_current_value(self):\n",
        "        if self.index >= len(self.iterable):\n",
        "            raise StopIteration\n",
        "        return self.iterable[self.index]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sample batch visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "BKwASN1g1vhF",
        "outputId": "0ea70946-54b0-489c-bfb8-d6449c735afa"
      },
      "outputs": [],
      "source": [
        "# Initialize the network\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset, transform=transformation,test=False)\n",
        "# Create a simple dataloader just for simple visualization\n",
        "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=15)\n",
        "\n",
        "# Extract one batch\n",
        "example_batch = next(iter(vis_dataloader))\n",
        "# Example batch is a list containing 3x11 images\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1], example_batch[2]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenated,nrow=15))\n",
        "print(f\"Anchor labels: {example_batch[3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Triplet Loss Function\n",
        "class TripletLoss(torch.nn.Module):\n",
        "    def __init__(self, margin =d_margin):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    \n",
        "    def forward(self, anchor, positive, negative):\n",
        "        #Calculate the eucidian distance and calculate the Triplet Loss\n",
        "        distance_positive = F.pairwise_distance(anchor, positive, keepdim=True)\n",
        "        distance_negative = F.pairwise_distance(anchor, negative, keepdim=True)\n",
        "\n",
        "        loss_triplet = torch.mean(F.relu(distance_positive - distance_negative + self.margin))\n",
        "\n",
        "        return loss_triplet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset, transform=transformation, test=False)\n",
        "train_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=d_batch_size)\n",
        "net = SiameseNetwork(d_latent).to(device)\n",
        "criterion = TripletLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_accruracy(net):\n",
        "    train_results = []\n",
        "    labels = []\n",
        "    net.eval()\n",
        "    siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test, transform=transformation)\n",
        "    # Create a simple dataloader just for simple visualization\n",
        "    vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=d_batch_size)\n",
        "    running_loss_test = []\n",
        "    loss_history_test = []\n",
        "    with torch.no_grad():\n",
        "        for epoch in range(0,1):\n",
        "            # Initialize the running loss\n",
        "            # Iterate over the batches in the dataloader\n",
        "            for i, (anchor_test, positive_test, negative_test, _) in enumerate(vis_dataloader):\n",
        "                # Transfer images and labels to the device\n",
        "                anchor_test, positive_test, negative_test = anchor_test.to(device), positive_test.to(device), negative_test.to(device)\n",
        "    \n",
        "                # Forward pass\n",
        "                output_anchor_test, output_positive_test, output_negative_test = [net.forward_once(anchor_test), net.forward_once(positive_test), net.forward_once(negative_test)]\n",
        "                # Calculate the triplet loss\n",
        "                loss_triplet_test = criterion(output_anchor_test, output_positive_test, output_negative_test)\n",
        "    \n",
        "                # Update the running loss\n",
        "                running_loss_test.append(loss_triplet_test.item())\n",
        "\n",
        "        return(np.sum(running_loss_test)/len(running_loss_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7bz8o__2JKn"
      },
      "outputs": [],
      "source": [
        "counter = []\n",
        "loss_history = [] \n",
        "iteration_no = 0\n",
        "# Training loop\n",
        "for epoch in range(d_no_epochs):\n",
        "    # Initialize the running loss\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Initialize the start time for the epoch\n",
        "    epoch_start_time = time.time()\n",
        "    \n",
        "    # Iterate over the batches in the dataloader\n",
        "    for i, (anchor, positive, negative,_)  in enumerate(train_dataloader):\n",
        "        # print(anchor,positive, negative, edgecase)\n",
        "        \"\"\" \"\"\" # Transfer images and labels to the device\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        output_anchor, output_positive, output_negative = net(anchor, positive, negative)\n",
        "        \n",
        "        # Calculate the triplet loss\n",
        "        loss_triplet = criterion(output_anchor, output_positive, output_negative)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss_triplet.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the running loss\n",
        "        running_loss += loss_triplet.item()\n",
        "\n",
        "        # Print the loss every 10 batches\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{d_no_epochs}] \\n\\tBatch [{i+1}/{len(train_dataloader)}] \\n\\tLoss: {running_loss / 10}\")\n",
        "            running_loss = 0.0\n",
        "        \n",
        "        iteration_no += 1\n",
        "        \n",
        "    loss_history.append(loss_triplet.item())\n",
        "    counter.append(iteration_no)\n",
        "    # End of epoch\n",
        "    # Calculate the epoch running time\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"\\tTime: {epoch_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training complete\n",
        "plt.plot(counter, loss_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"Training finished.\")\n",
        "\n",
        "\"\"\" # Training complete\n",
        "plt.plot(test_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Testing Loss')\n",
        "plt.title('Testing Loss over Epochs')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"Training finished.\") \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tQwDDYT52JTX",
        "outputId": "7f1c6518-fd64-49b3-b1d1-f7ee44807387"
      },
      "outputs": [],
      "source": [
        "# Load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
        "                                        transform=transformation)\n",
        "test_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(test_dataloader)\n",
        "anchor, positive, negative, _ = next(dataiter)\n",
        "\n",
        "for i in range(10):\n",
        "    # Iterate over 10 images and test them with the first image (x0)\n",
        "    anchor, positive, negative, _ = next(dataiter)\n",
        "\n",
        "    # Concatenate the two images together\n",
        "    concatenated = torch.cat((anchor, positive, negative), 0)\n",
        "    \n",
        "    output_anchor, output_positive, output_negative = net(anchor.to(device), positive.to(device), negative.to(device))\n",
        "    euclidean_distance_positive = F.pairwise_distance(output_anchor, output_positive)\n",
        "    euclidean_distance_negative = F.pairwise_distance(output_anchor, output_negative)\n",
        "    imshow(torchvision.utils.make_grid(concatenated), f'Intracluster distance: {euclidean_distance_positive.item():.2f} -- Intercluster distance: {euclidean_distance_negative.item():.2f}')\n",
        "print(output_anchor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnArRrUDK8hi"
      },
      "outputs": [],
      "source": [
        "#torch.save({\"model_state_dict\": net.state_dict(),\"optimizer_state_dict\": optimizer.state_dict()}, \"trained_model.pth\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization of Latent space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset, transform=transformation)\n",
        "train_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "dataiter = iter(train_dataloader)\n",
        "anchor, positive, negative, _ = next(dataiter)\n",
        "pos_dist = []\n",
        "neg_dist = []\n",
        "print(len(train_dataloader))\n",
        "for i in range(len(train_dataloader)-1):\n",
        "    # Iterate over 10 images and test them with the first image (x0)\n",
        "    anchor, positive, negative, _ = next(dataiter)\n",
        "\n",
        "    output_anchor, output_positive, output_negative = net.forward_once(anchor.to(device)), net.forward_once(positive.to(device)), net.forward_once(negative.to(device))\n",
        "    euclidean_distance_positive = F.pairwise_distance(output_anchor, output_positive)\n",
        "    euclidean_distance_negative = F.pairwise_distance(output_anchor, output_negative)\n",
        "    # print(euclidean_distance_positive)\n",
        "    pos_dist.append(euclidean_distance_positive.detach().cpu().numpy())\n",
        "    neg_dist.append(euclidean_distance_negative.detach().cpu().numpy())\n",
        "\n",
        "pos_dist = [x[0] for x in pos_dist]\n",
        "neg_dist = [x[0] for x in neg_dist]\n",
        "\n",
        "# Combine positive and negative distances for the box plot\n",
        "distances = [pos_dist, neg_dist]\n",
        "\n",
        "distance_data = {'Pos Dist':pos_dist,'Neg Dist':neg_dist}\n",
        "df_train = pd.DataFrame(distance_data)\n",
        "df_train.head()\n",
        "\n",
        "# Set the style of the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create the box plot using seaborn\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.boxplot(data=df_train,orient='h')\n",
        "\n",
        "# Set the labels for x-axis and y-axis\n",
        "plt.xlabel('Distance Type')\n",
        "plt.ylabel('Distance')\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Box Plot of Positive and Negative Distances')\n",
        "\n",
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load it into the SiameseNetworkDataset\n",
        "\n",
        "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test, transform=transformation,test = True)\n",
        "test_dataloader = DataLoader(siamese_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Grab one image that we are going to test\n",
        "net.eval()\n",
        "dist_positive_test = []\n",
        "print(len(test_dataloader))\n",
        "dataiter = iter(test_dataloader)\n",
        "with torch.no_grad():\n",
        "    while True:\n",
        "        try:\n",
        "            anchor, positive, positive_test, _ = next(dataiter)\n",
        "\n",
        "            output_anchor = net.forward_once(anchor.to(device))\n",
        "            output_positive_test = net.forward_once(positive_test.to(device))\n",
        "            distance_anchor_positive_test = F.pairwise_distance(output_anchor, output_positive_test)\n",
        "            dist_positive_test.append(distance_anchor_positive_test.detach().cpu().numpy())\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "\n",
        "dist_positive_test = [x[0] for x in dist_positive_test]\n",
        "\n",
        "# Combine positive and negative distances for the box plot\n",
        "distances = [dist_positive_test]\n",
        "\n",
        "distance_data = {'Pos Test Dist' :dist_positive_test}\n",
        "df_test = pd.DataFrame(distance_data)\n",
        "df_test.head()\n",
        "print(f\"Threshold: {df_train['Pos Dist'].quantile(0.75)}\")\n",
        "print(len(df_test[df_test['Pos Test Dist'] < df_train['Pos Dist'].quantile(0.75)])/len(df_test))\n",
        "\n",
        "df_train.describe()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOuUs+vkPNCQj5Gz+GQVKU9",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "014_siameseNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
